```md
# CapsResNet: A Hybrid Residual Capsule Network for Image Classification

This repository provides the **CapsResNet** model, a hybrid architecture combining **Residual Networks (ResNet) and Capsule Networks** for image classification. The model supports **FashionMNIST, EMNIST, CIFAR10, CIFAR100, and SVHN**.

This work is fully **reproducible** with clear **documentation, public source code, and dataset usage instructions**.

## ğŸ“Œ Features
âœ”ï¸ **ResNet + Capsule Network** combination  
âœ”ï¸ **Supports multiple datasets**  
âœ”ï¸ **Easy to train and test**  
âœ”ï¸ **Fully open-source and reproducible**  

---

## ğŸ“Œ Installation

### **1ï¸âƒ£ Install Dependencies**
Ensure Python **3.10 or 3.11** is installed (Python 3.13 is **not** supported).  
Then, install the dependencies:

```bash
pip install -r requirements.txt
```

> **Windows Users:** Install **Microsoft Visual C++ Redistributable** if needed:  
> [Download VC++ 2019 (x64)](https://aka.ms/vs/16/release/vc_redist.x64.exe)

### **2ï¸âƒ£ Install PyTorch**
For **GPU (CUDA 12.1)**:
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```
For **CPU only**:
```bash
pip install torch torchvision torchaudio
```

---

## ğŸ“Œ Usage

### **1ï¸âƒ£ Training the Model**
Run the training script:
```bash
python train.py
```
This will:
- Load the dataset
- Train the **CapsResNet** model
- Save the trained model as `capsresnet_{DATASET_NAME}.pth`

#### **ğŸ›  Selecting a Dataset**
Modify `train.py` to choose a dataset:
```python
DATASET_NAME = "CIFAR10"  # Options: "FashionMNIST", "EMNIST", "CIFAR10", "CIFAR100", "SVHN"
```

### **2ï¸âƒ£ Evaluating the Model**
After training, test the model using:
```bash
python test.py
```
This loads the saved model and computes accuracy on the test set.

---

## ğŸ“Œ Datasets
This model supports **5 datasets**:

| Dataset       | Classes | Image Size | Type |
|--------------|---------|------------|------|
| FashionMNIST | 10      | 28x28      | Grayscale |
| EMNIST       | 47      | 28x28      | Grayscale |
| CIFAR10      | 10      | 32x32      | Color (RGB) |
| CIFAR100     | 100     | 32x32      | Color (RGB) |
| SVHN         | 10      | 32x32      | Color (RGB) |

Each dataset is **automatically downloaded** when running `train.py`.

---

## ğŸ“Œ Code Structure
The repository is **modularized** for clarity:

```
CapsResNet-Classification/
â”‚â”€â”€ models/
â”‚   â”œâ”€â”€ residual_block.py      # Defines Residual Block
â”‚   â”œâ”€â”€ capsule_layer.py       # Defines Capsule Layer
â”‚   â”œâ”€â”€ caps_resnet.py         # Full CapsResNet model
â”‚â”€â”€ utils/
â”‚   â”œâ”€â”€ dataset_loader.py      # Loads datasets
â”‚   â”œâ”€â”€ training.py            # Training logic
â”‚   â”œâ”€â”€ evaluation.py          # Evaluation logic
â”‚â”€â”€ train.py                    # Main training script
â”‚â”€â”€ test.py                     # Model evaluation
â”‚â”€â”€ requirements.txt            # Dependencies
â”‚â”€â”€ README.md                   # Documentation
â”‚â”€â”€ LICENSE                     # License (MIT)
```

---

## ğŸ“Œ Reproducibility
To ensure **reproducibility**, we provide:
- **Fixed Random Seeds**: The code sets a **seed** for deterministic behavior.
- **Complete Code and Documentation**: All training parameters and datasets are described.
- **Public Model Checkpoints**: The trained models are available.

You can manually set a **random seed** in `train.py`:
```python
import torch
import numpy as np
import random

seed = 42  # Change this for different results
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)
```

---

## ğŸ“Œ Citation
If you use this work, please cite:

```
@article{your_paper,
  title={CapsResNet: A Hybrid Residual Capsule Network for Image Classification},
  author={Your Name(s)},
  journal={The Visual Computer},
  year={2025},
  publisher={Springer}
}
```

We have also included a **citation format** inside our **GitHub repository description** as required by the journal editor.

---

## ğŸ“Œ License
This project is released under the **MIT License**. You are free to **use, modify, and distribute** it.

```
MIT License

Permission is hereby granted, free of charge, to any person obtaining a copy of this software...
```

---
